Um programa em java foi utilizado para pr√© processar os dados. Esse programa tem fun√ß√µes para calcular:

- a frequencia de cada palavra em um set de arquivos
- a quantidade de arquivos em que cada palavra aparece
- o tf-idf de cada palavra

Esse valores s√£o sempre calculados separadamente para os arquivos positivos e os negativos. Ap√≥s realizar os c√°lculos e analisar os resultados, conclu√≠mos que nesse caso o c√°lculo do tf-idf n√£o seria muito eficiente, visto que as palavras que possu√≠am o tf-idf mais alto, apareciam em somente um arquivo.

Esses dados foram utilizados ent√£o como entrada pelo programa em java para criar os arquivos: diff_narq(2) e diff_frequency(2) que representam a diferen√ßa entreos arquivos positivos e negativos do n√∫mero de arquivos em que uma palavra aparece e da frequencia de cada palavra respectivamente.

A partir desses arquivos para a parte 1 e 2, 100 palavras foram escohidas para serem utilizadas no bag-of-words.

Ap√≥s escolher as palavras, todos os arquivos foram sem pontua√ß√£o foram passados por um parser que removeu todas as palavras que n„o estavam na seleÁ„o feita, e cada ocorr√™ncia de uma palavra existente no bag of words se tornava um token. Os arquivos dos tokens eram passados novamente pelo java, que contava as inst√¢ncias, transformando em uma inst√¢ncia do Weka.